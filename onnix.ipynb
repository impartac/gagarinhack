{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader,dataset,ConcatDataset\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.ops.boxes import nms\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(r\"C:\\Users\\32233\\PycharmProjects\\temp\\runs\\detect\\train29\\weights\\best_detect.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.8.19 torch-2.2.2 CPU (12th Gen Intel Core(TM) i9-12900H)\n",
      "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\32233\\PycharmProjects\\temp\\runs\\detect\\train29\\weights\\best_detect.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.2s, saved as 'C:\\Users\\32233\\PycharmProjects\\temp\\runs\\detect\\train29\\weights\\best_detect.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (4.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\32233\\PycharmProjects\\temp\\runs\\detect\\train29\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=C:\\Users\\32233\\PycharmProjects\\temp\\runs\\detect\\train29\\weights\\best_detect.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=C:\\Users\\32233\\PycharmProjects\\temp\\runs\\detect\\train29\\weights\\best_detect.onnx imgsz=640 data=C:\\Users\\32233\\PycharmProjects\\temp\\datasets\\data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\32233\\\\PycharmProjects\\\\temp\\\\runs\\\\detect\\\\train29\\\\weights\\\\best_detect.onnx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format='onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
